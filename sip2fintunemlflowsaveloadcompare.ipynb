{"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4b7718a458614aff92d24a9ce6d23f5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7557300ab21849389f0c671e9d9ca1da","IPY_MODEL_98a799b515844654a70acea435236104","IPY_MODEL_e6c8cf0943c943d58fef0e7570644a08"],"layout":"IPY_MODEL_7063ac913e134c6784c3d7247d813bde"}},"7557300ab21849389f0c671e9d9ca1da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ad1adc2de904647b369be5b9b635441","placeholder":"​","style":"IPY_MODEL_e7a6e429333f4be0a13977f31fafa8b8","value":"Map: 100%"}},"98a799b515844654a70acea435236104":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e595788a743421999569ee2dc2f99ab","max":4924,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2f3cf1af780401686c32a101fbb6328","value":4924}},"e6c8cf0943c943d58fef0e7570644a08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb112071fe1b42d48f926655e4231096","placeholder":"​","style":"IPY_MODEL_82a8a97cb4e340b188a227ebc6fdb2a1","value":" 4924/4924 [00:00&lt;00:00, 19863.96 examples/s]"}},"7063ac913e134c6784c3d7247d813bde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ad1adc2de904647b369be5b9b635441":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7a6e429333f4be0a13977f31fafa8b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e595788a743421999569ee2dc2f99ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2f3cf1af780401686c32a101fbb6328":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb112071fe1b42d48f926655e4231096":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82a8a97cb4e340b188a227ebc6fdb2a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a9f3c7b60814dcfab0a792a70d2d5d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ecd3061ba3c841aaa99a562d6968d95b","IPY_MODEL_6627c48413784b1f94bd4b4fa5a7e0cf","IPY_MODEL_0a4eb293783542ccb6059c695d8ca2c3"],"layout":"IPY_MODEL_424b732f2528454fa7511e981945fb2f"}},"ecd3061ba3c841aaa99a562d6968d95b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_894a344bce234b30905dc63882f0347b","placeholder":"​","style":"IPY_MODEL_ba44a682d4ac4cb7a959822c54d3bc19","value":"Loading checkpoint shards: 100%"}},"6627c48413784b1f94bd4b4fa5a7e0cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0058631ae40043baa0364ba5afe5d5da","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f96b9a68d52647db8347199232d2261b","value":3}},"0a4eb293783542ccb6059c695d8ca2c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19311d0ff38f413186b655c22d3cc236","placeholder":"​","style":"IPY_MODEL_cc29a3a658504fbb8282924f0d6f4512","value":" 3/3 [00:08&lt;00:00,  2.87s/it]"}},"424b732f2528454fa7511e981945fb2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"894a344bce234b30905dc63882f0347b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba44a682d4ac4cb7a959822c54d3bc19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0058631ae40043baa0364ba5afe5d5da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f96b9a68d52647db8347199232d2261b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19311d0ff38f413186b655c22d3cc236":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc29a3a658504fbb8282924f0d6f4512":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4d9a3e64fa140e79b2adcd7d021c888":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3dbdf0498da2452ab7f0e358d6751e13","IPY_MODEL_a8ef5d1a3ee04677a37eac56cde44bcd","IPY_MODEL_45d81eb10acf478ba2dc693fdca41699"],"layout":"IPY_MODEL_ae485dbd965748948e0a0948979c42c9"}},"3dbdf0498da2452ab7f0e358d6751e13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_325eb0a1ff29493581c3adf528688193","placeholder":"​","style":"IPY_MODEL_677188aa140d42f19a1a28d3b09edd25","value":"Map: 100%"}},"a8ef5d1a3ee04677a37eac56cde44bcd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da71c9fec8174490a7c86682d5ebaa2a","max":4924,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80caea88a6824aaaaccd2703074b990f","value":4924}},"45d81eb10acf478ba2dc693fdca41699":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82f662070abd4d35b2058892315c3790","placeholder":"​","style":"IPY_MODEL_8fdd112667804493b65d428bd59de7fd","value":" 4924/4924 [00:01&lt;00:00, 3996.43 examples/s]"}},"ae485dbd965748948e0a0948979c42c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"325eb0a1ff29493581c3adf528688193":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"677188aa140d42f19a1a28d3b09edd25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da71c9fec8174490a7c86682d5ebaa2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80caea88a6824aaaaccd2703074b990f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82f662070abd4d35b2058892315c3790":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fdd112667804493b65d428bd59de7fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9010657,"sourceType":"datasetVersion","datasetId":5428923}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Step 1: Installing and importing the libraries","metadata":{"id":"rW6ZDBZa2a95"}},{"cell_type":"code","source":"!pip install google-cloud-storage>=2.2.1\n!pip install transformers\n!pip install bitsandbytes\n!pip install peft\n!pip install trl\n!pip install accelerate\n!pip install datasets\n!pip install mlflow==2.15.0","metadata":{"id":"4yEGJoghOvJ3","execution":{"iopub.status.busy":"2024-08-01T07:28:00.407448Z","iopub.execute_input":"2024-08-01T07:28:00.407786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport transformers\n# from trl import SFTTrainer\nfrom peft import (LoraConfig, get_peft_model, prepare_model_for_kbit_training)\nfrom datasets import load_dataset\nfrom transformers import (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline)\nimport pandas as pd\nfrom datasets import load_dataset, Dataset","metadata":{"id":"BAzFpLeXO-hN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Step 2: Preparing the data\n","metadata":{"id":"DjbUkNZq2ut1"}},{"cell_type":"code","source":"!ls /kaggle/input/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the financial dataset\nfile_path = '/kaggle/input/ValorizationData.xlsx'  # Update with the correct path if different\ndf = pd.read_excel(file_path)\n\n# Display the first few rows of the dataframe\n# print(df.head())\n\n# Preprocessing: Handle missing values and prepare inputs and targets\ndf.fillna('', inplace=True)\n\n# Translate column names if not done already\ndf.rename(columns={\n    'Saphyr Reference': 'Référence Saphyr',\n    'Year': 'Année',\n    'Month': 'Mois',\n    'Forecast_M-1 (Cost)': 'Prévision_M-1 (Coût)',\n    'Valorization (Cost)': 'Valorisation (Coût)',\n    'Forecast_M-1 (Days)': 'Prévision_M-1 (Jours)',\n    'Valorization (Days)': 'Valorisation (Jours)',\n    'Forecast_M-1 (Margin%)': 'Prévision_M-1 (Marge%)',\n    'Valorization (Margin%)': 'Valorisation (Marge%)',\n    'Forecast_M-1 (Turnover)': 'Prévision_M-1 (Chiffre d’affaires)',\n    'Valorization (Turnover)': 'Valorisation (Chiffre d’affaires)',\n    'ValorizationComment': 'Commentaire de Valorisation'\n}, inplace=True)\n\ndf = df[df['Commentaire de Valorisation'].str.len() >= 30]\ndf.head(5)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":504},"id":"fiQkXQlWO-j-","outputId":"ec707bf2-aa77-4f63-8d25-ad3a69f893ca","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the text field in French\ndf['text'] = df.apply(lambda row: (\n    f\"\"\"Projet {row['Référence Saphyr']} en {row['Année']}-{row['Mois']}\n    avec des coûts prévisionnels de {row['Prévision_M-1 (Coût)']}, des coûts de valorisation de {row['Valorisation (Coût)']},\n    des jours prévisionnels de {row['Prévision_M-1 (Jours)']}, des jours de valorisation de {row['Valorisation (Jours)']},\n    une marge prévisionnelle de {row['Prévision_M-1 (Marge%)']}, une marge de valorisation de {row['Valorisation (Marge%)']},\n    un chiffre d'affaires prévisionnel de {row['Prévision_M-1 (Chiffre d’affaires)']},\n    un chiffre d'affaires de valorisation de {row['Valorisation (Chiffre d’affaires)']}.\"\"\"\n), axis=1)\n\n# Display the first few rows to verify the changes\n# Set display option to show full text in columns\npd.set_option('display.max_colwidth', None)\nprint(df[['Référence Saphyr', 'text']].head())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUzT_-00aiZm","outputId":"7588eb25-1f61-4d27-ef90-1e669c80b2a5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define input and target columns\ninputs = df['text'].tolist()\ntargets = df['Commentaire de Valorisation'].tolist()\n\n# Create a dataset\ndata = {\n    'text': inputs,\n    'target_text': targets\n}\n\ndataset = Dataset.from_pandas(pd.DataFrame(data))\n\n# Split the dataset into training and validation sets\n# train_test_split = dataset.train_test_split(test_size=0.1)\n# train_dataset = train_test_split['train']\n# val_dataset = train_test_split['test']\n\n# train_dataset = dataset","metadata":{"id":"m7hGJY8CZN9W","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w_SyKmMVO-mk","outputId":"81983da8-b5fa-455f-ab70-25af8b7940ec","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset[0])  # Inspect the first sample\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"srf7Xqe6WDUK","outputId":"2ab2098d-14e2-45e4-f2f2-d529cea206ee","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the response template for the solutions\nresponse_template = \"### Analyse financière du projet:\"\n\ndef create_text_field(sample):\n  return {\n      \"text\": f\"{sample['text']}\\n{response_template} {sample['target_text']}\"\n    }\n\ndataset = dataset.map(create_text_field, remove_columns=dataset.features, batched=False)\n\nprint(dataset[0])\nprint(len(dataset))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["4b7718a458614aff92d24a9ce6d23f5f","7557300ab21849389f0c671e9d9ca1da","98a799b515844654a70acea435236104","e6c8cf0943c943d58fef0e7570644a08","7063ac913e134c6784c3d7247d813bde","7ad1adc2de904647b369be5b9b635441","e7a6e429333f4be0a13977f31fafa8b8","3e595788a743421999569ee2dc2f99ab","e2f3cf1af780401686c32a101fbb6328","bb112071fe1b42d48f926655e4231096","82a8a97cb4e340b188a227ebc6fdb2a1"]},"id":"oeUNCor9O-pN","outputId":"6b07782c-6379-4032-d99b-72c441e40370","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTAsVahwO-ro","outputId":"e466b8ad-a50e-4023-a83c-353144746b0b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3: Login to Hugging Face","metadata":{"id":"KO4KCnB33HOq"}},{"cell_type":"code","source":"# Login into our HF account using our token\nfrom huggingface_hub import login\n# from google.colab import userdata\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\n\nlogin(\n  token=secret_value_0, # Retrieve my HF_TOKEN stored in Google Colab Secrets\n  # add_to_git_credential=True\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WqMS5Vc-dzdY","outputId":"331a518c-451a-425f-a247-1e0b3bc1c976","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4: Loading the model","metadata":{"id":"xbMQlHUY3Px0"}},{"cell_type":"code","source":"# BitsAndBytesConfig for 4-bit integers\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=getattr(torch, \"float16\")\n)\n\npretrained_model_name = \"instruction-pretrain/finance-Llama3-8B\"\n# aboonaji/llama2finetune-v2\nllama_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path = pretrained_model_name,\n                                                   quantization_config = bnb_config)\n\nllama_model.config.use_cache = False\n# llama_model.config.pretraining_tp = 1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":190,"referenced_widgets":["0a9f3c7b60814dcfab0a792a70d2d5d3","ecd3061ba3c841aaa99a562d6968d95b","6627c48413784b1f94bd4b4fa5a7e0cf","0a4eb293783542ccb6059c695d8ca2c3","424b732f2528454fa7511e981945fb2f","894a344bce234b30905dc63882f0347b","ba44a682d4ac4cb7a959822c54d3bc19","0058631ae40043baa0364ba5afe5d5da","f96b9a68d52647db8347199232d2261b","19311d0ff38f413186b655c22d3cc236","cc29a3a658504fbb8282924f0d6f4512"]},"id":"zlXssJEIO-u9","outputId":"255013bd-516c-4536-d6c7-dd07cccdddbe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5: Loading the tokenizer","metadata":{"id":"EJbJ3fAg3V6x"}},{"cell_type":"code","source":"\n# Load and configure the tokenizer\nllama_tokenizer = AutoTokenizer.from_pretrained(\n    pretrained_model_name_or_path=pretrained_model_name,\n    use_fast=True,\n    trust_remote_code=True\n)\n\n# Set special tokens\nif llama_tokenizer.pad_token is None:\n    llama_tokenizer.pad_token = llama_tokenizer.eos_token\n\nif llama_tokenizer.bos_token is None:\n    llama_tokenizer.bos_token = llama_tokenizer.cls_token\n\nif llama_tokenizer.sep_token is None:\n    llama_tokenizer.sep_token = llama_tokenizer.cls_token\n\nllama_tokenizer.padding_side = \"right\"\n\n","metadata":{"id":"nG5rG7c4PeUs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"llama_tokenizer.padding_side = \"right\"\n\n# Verify the configuration\nprint(f\"PAD token: {llama_tokenizer.pad_token}\")\nprint(f\"EOS token: {llama_tokenizer.eos_token}\")\nprint(f\"BOS token: {llama_tokenizer.bos_token}\")\nprint(f\"SEP token: {llama_tokenizer.sep_token}\")\n\n# Test tokenization\ntest_text = \"Voici un texte à tester.\"\ntokens = llama_tokenizer(test_text)\nprint(tokens)\ndecoded_text = llama_tokenizer.decode(tokens['input_ids'])\nprint(decoded_text)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lO3M_iPDgfOm","outputId":"c69f9051-880f-4542-e50b-ae3c2e9f82c7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6: Setting the training arguments","metadata":{"id":"o8lpjfKa3imc"}},{"cell_type":"code","source":"\nimport mlflow\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom datetime import datetime\n# LoRA config based on QLoRA paper & Sebastian Raschka experiment\n\npeft_config = LoraConfig(\n    lora_alpha=16,       # Moderate alpha for balanced scaling\n    lora_dropout=0.05,   # Standard dropout to avoid overfitting\n    r=64,                # Moderate rank for expressiveness\n    bias=\"none\",         # No bias adaptation\n    task_type=\"CAUSAL_LM\",\n    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj']  # Key projection layers for adaptation\n)\n\n# Define training arguments for lower memory usage\ntraining_arguments = TrainingArguments(\n    # Set this to mlflow for logging your training\n    report_to=\"mlflow\",\n    output_dir=\"./results\",\n    # evaluation_strategy=\"steps\",\n    # do_eval=True,\n    optim=\"adamw_torch\",  # Use a simpler optimizer\n    per_device_train_batch_size=1,  # Reduce batch size to fit memory constraints\n    gradient_accumulation_steps=16,  # Increase accumulation steps to compensate for small batch size\n    per_device_eval_batch_size=1,  # Reduce eval batch size\n    log_level=\"info\",\n    save_steps=50,  # Save less frequently if needed\n    logging_steps=25,  # Log less frequently to reduce overhead\n    learning_rate=1e-4,  # Use a lower learning rate\n    # eval_steps=100,  # Evaluate less frequently\n    num_train_epochs=1,  # Reduce the number of epochs for quick testing\n    max_steps=500,  # Limit the total number of steps for quick testing\n    warmup_steps=50,  # Reduce warmup steps\n    lr_scheduler_type=\"linear\",\n    fp16=True,  # Enable mixed-precision training\n    # Name the MLflow run\n    run_name=f\"{pretrained_model_name}-QLoRA-{datetime.now().strftime('%Y-%m-%d-%H-%M-%s')}\",\n)\n\n\npeft_model = get_peft_model(llama_model, peft_config)\npeft_model.print_trainable_parameters()\n\n\n\n# training_arguments = TrainingArguments(output_dir = \"./results\", per_device_train_batch_size = 4, max_steps = 100)","metadata":{"id":"2CdZcZZIPecB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 7: Tokenize the dataset","metadata":{"id":"k3sbaq1Z3tHy"}},{"cell_type":"code","source":"# Tokenize the dataset\ndef tokenize_function(sample):\n    return llama_tokenizer(\n        sample['text'],\n        truncation=True,\n        padding=\"max_length\",  # Use \"max_length\" if consistent length is needed\n        max_length=512  # Adjust based on your model's expected input size\n    )\n\n# Apply tokenization\ntokenized_dataset = dataset.map(tokenize_function, batched=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["e4d9a3e64fa140e79b2adcd7d021c888","3dbdf0498da2452ab7f0e358d6751e13","a8ef5d1a3ee04677a37eac56cde44bcd","45d81eb10acf478ba2dc693fdca41699","ae485dbd965748948e0a0948979c42c9","325eb0a1ff29493581c3adf528688193","677188aa140d42f19a1a28d3b09edd25","da71c9fec8174490a7c86682d5ebaa2a","80caea88a6824aaaaccd2703074b990f","82f662070abd4d35b2058892315c3790","8fdd112667804493b65d428bd59de7fd"]},"id":"gdhdtY3gyMPh","outputId":"f1e56a57-b55b-4a66-cea7-0cccfe511451","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokenized_dataset[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zX1fNGX8yMS7","outputId":"f4042c80-8b39-44bd-e723-47533af0788b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 8: Creating the Fine-Tuning trainer","metadata":{"id":"iFEvM38L3yE-"}},{"cell_type":"code","source":"# llama_trainer = SFTTrainer(model = llama_model,\n#                                args = training_arguments,\n#                                train_dataset = tokenized_dataset,\n#                                peft_config=peft_config,\n#                                tokenizer = llama_tokenizer,\n#                                dataset_text_field = \"text\")\n\nllama_trainer = transformers.Trainer(\n    model=peft_model,\n    train_dataset=tokenized_dataset,\n    data_collator=transformers.DataCollatorForLanguageModeling(llama_tokenizer, mlm=False),\n    args=training_arguments,\n)\n\n# use_cache=True is incompatible with gradient checkpointing.\npeft_model.config.use_cache = False","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5y_JjJtryfoe","outputId":"d891406d-2e98-4356-8f7d-4a9a0b3dc28d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 9: Training the model","metadata":{"id":"MdlFlVE637ug"}},{"cell_type":"code","source":"llama_trainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"MLCP-wSlPs0A","outputId":"e7653418-2271-4c12-a40f-451d76135723","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 10: Save the model and the tokenizer","metadata":{"id":"PmAKKqzd4B1-"}},{"cell_type":"code","source":"# Define the output directory\noutput_dir = \"./saved_model\"\n\n# Save the model\n# llama_sft_trainer.save_model(output_dir)\n\n# Save the tokenizer\n# llama_tokenizer.save_pretrained(output_dir)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hkg-g81Npm24","outputId":"b61e68c8-ee02-45d8-a1e1-9545bc7bd7ec","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## mlFlow save model","metadata":{}},{"cell_type":"code","source":"import mlflow\n\n# Get the ID of the MLflow Run that was automatically created above\nlast_run_id = mlflow.last_active_run().info.run_id\n\n# Save a tokenizer without padding because it is only needed for training\ntokenizer_no_pad = AutoTokenizer.from_pretrained(llama_model, add_bos_token=True)\n\n# If you interrupt the training, uncomment the following line to stop the MLflow run\n# mlflow.end_run()\n\nwith mlflow.start_run(run_id=last_run_id):\n    mlflow.log_params(peft_config.to_dict())\n    mlflow.transformers.log_model(\n        transformers_model={\"model\": llama_trainer.model, \"tokenizer\": llama_tokenizer},\n#         prompt_template=prompt_template,\n#         signature=signature,\n        artifact_path=\"model\",  # This is a relative path to save model files within MLflow run\n    )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## mlFlow load model","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## mlFlow Compare Metrics Model","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 11: Testing the model","metadata":{"id":"gammzMKt4OtN"}},{"cell_type":"code","source":"# Define the improved prompt template\ndef create_financial_prompt(data):\n    return (\n        f\"Analyse financière pour le projet {data['Référence Saphyr']} en {data['Année']}-{data['Mois']}:\\n\"\n        f\"- Coûts prévisionnels: {data['Prévision_M-1 (Coût)']}\\n\"\n        f\"- Coûts de valorisation: {data['Valorisation (Coût)']}\\n\"\n        f\"- Jours prévisionnels: {data['Prévision_M-1 (Jours)']}\\n\"\n        f\"- Jours de valorisation: {data['Valorisation (Jours)']}\\n\"\n        f\"- Marge prévisionnelle: {data['Prévision_M-1 (Marge%)']}\\n\"\n        f\"- Marge de valorisation: {data['Valorisation (Marge%)']}\\n\"\n        f\"- Chiffre d'affaires prévisionnel: {data['Prévision_M-1 (Chiffre d’affaires)']}\\n\"\n        f\"- Chiffre d'affaires de valorisation: {data['Valorisation (Chiffre d’affaires)']}\\n\\n\"\n        \"Veuillez analyser les éléments suivants en français:\\n\"\n        \"1. Peux tu analyser la valorisation Mensuelle et me fournir des conseils\\n\"\n        \"2. Peux tu analyser la prévision mensuel et me fournir des conseils \\n\"\n        \"Merci de fournir une analyse détaillée en français.\"\n\n    )\n\n# Example financial data row (replace with the provided values)\nexample_data = {\n    'Référence Saphyr': 'PB-00008',\n    'Année': 2023,\n    'Mois': 12,\n    'Prévision_M-1 (Coût)': '-22,083.00 €',\n    'Valorisation (Coût)': '-20,810.00 €',\n    'Prévision_M-1 (Jours)': 86.94,\n    'Valorisation (Jours)': 81.25,\n    'Prévision_M-1 (Marge%)': '28.25 %',\n    'Valorisation (Marge%)': '16.27 %',\n    'Prévision_M-1 (Chiffre d’affaires)': '30,777.00 €',\n    'Valorisation (Chiffre d’affaires)': '24,852.50 €'\n}\n# Create the improved prompt\nfinancial_prompt = create_financial_prompt(example_data)\n","metadata":{"id":"11-P56jZTwqg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"financial_prompt","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"id":"BmUkERehTwtB","outputId":"0525ce21-1ad2-4add-80a5-b32bf852aa96","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\n# Initialize the text generation pipeline\ntext_generation_pipeline = pipeline(task=\"text-generation\", model=llama_model, tokenizer=llama_tokenizer, max_length=700)\n\n# Generate a response\nmodel_answer = text_generation_pipeline(f\"<s>[INST] {financial_prompt} [/INST]\")\n\n# Print the generated analysis\nprint(model_answer[0]['generated_text'])\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i8s8M9OBXQJZ","outputId":"7ebb59c7-e6bc-4bda-9cb3-71cb30fefc43","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install Gradio\n!pip install gradio\n\nimport gradio as gr\nimport pandas as pd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ILSnK-JXTwye","outputId":"2df2466d-37cb-4d62-8cd9-9c64953f12a7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the financial dataset\nfile_path = '/kaggle/input/ValorizationData.xlsx'  # Update with the correct path if different\ndf = pd.read_excel(file_path)\n\n# Translate column names if not done already\ndf.rename(columns={\n    'Saphyr Reference': 'Référence Saphyr',\n    'Year': 'Année',\n    'Month': 'Mois',\n    'Forecast_M-1 (Cost)': 'Prévision_M-1 (Coût)',\n    'Valorization (Cost)': 'Valorisation (Coût)',\n    'Forecast_M-1 (Days)': 'Prévision_M-1 (Jours)',\n    'Valorization (Days)': 'Valorisation (Jours)',\n    'Forecast_M-1 (Margin%)': 'Prévision_M-1 (Marge%)',\n    'Valorization (Margin%)': 'Valorisation (Marge%)',\n    'Forecast_M-1 (Turnover)': 'Prévision_M-1 (Chiffre d’affaires)',\n    'Valorization (Turnover)': 'Valorisation (Chiffre d’affaires)',\n    'ValorizationComment': 'Commentaire de Valorisation'\n}, inplace=True)\n\n# Initialize the text generation pipeline\ntext_generation_pipeline = pipeline(task=\"text-generation\", model=llama_model, tokenizer=llama_tokenizer, max_length=500)\n\n# Function to extract data based on project name\ndef extract_data(project_name):\n    project_data = df[df['Référence Saphyr'] == project_name].iloc[0].to_dict()\n    # Return the 8 fields as a list\n    return [\n        project_data['Année'], project_data['Mois'], project_data['Prévision_M-1 (Coût)'],\n        project_data['Valorisation (Coût)'], project_data['Prévision_M-1 (Jours)'],\n        project_data['Valorisation (Jours)'], project_data['Prévision_M-1 (Marge%)'],\n        project_data['Valorisation (Marge%)'], project_data['Prévision_M-1 (Chiffre d’affaires)'],\n        project_data['Valorisation (Chiffre d’affaires)']\n    ]\n\n# Function to create prompt and generate analysis\ndef generate_analysis(project_name):\n    data = extract_data(project_name)\n    financial_prompt = (\n        f\"Analyse financière pour le projet {project_name} en {data[0]}-{data[1]}:\\n\"\n        f\"- Coûts prévisionnels: {data[2]}\\n\"\n        f\"- Coûts de valorisation: {data[3]}\\n\"\n        f\"- Jours prévisionnels: {data[4]}\\n\"\n        f\"- Jours de valorisation: {data[5]}\\n\"\n        f\"- Marge prévisionnelle: {data[6]}\\n\"\n        f\"- Marge de valorisation: {data[7]}\\n\"\n        f\"- Chiffre d'affaires prévisionnel: {data[8]}\\n\"\n        f\"- Chiffre d'affaires de valorisation: {data[9]}\\n\\n\"\n        \"Veuillez analyser les éléments suivants en français:\\n\"\n        \"1. Analysez la valorisation mensuelle et fournissez des conseils.\\n\"\n        \"2. Analysez la prévision mensuelle et fournissez des conseils.\\n\"\n        \"Merci de fournir une analyse détaillée en français.\"\n    )\n    response = text_generation_pipeline(f\"<s>[INST] {financial_prompt} [/INST]\")\n    return response[0]['generated_text']","metadata":{"id":"axRbPLshTw1_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":790},"id":"cC0A1qOieTTa","outputId":"a22066a5-2e12-4bef-bc33-efd0a0804e7e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 12: Create a Gradio interface","metadata":{"id":"fhqWT1qJ4YOq"}},{"cell_type":"code","source":"# Define Gradio interface\nproject_dropdown = gr.Dropdown(label=\"Sélectionnez le projet\", choices=df['Référence Saphyr'].unique().tolist())\noutput_textbox = gr.Textbox(label=\"Analyse\", lines=10)\n\ndef on_submit(project_name):\n    return generate_analysis(project_name)\n\n# Build the Gradio interface\napp = gr.Interface(\n    fn=on_submit,\n    inputs=[project_dropdown,\n            gr.Slider(label=\"Longueur maximale de la réponse\", minimum=50, maximum=1000, value=200, step=10)  # Slider for max_length\n            ],\n    outputs=[output_textbox],\n    title=\"Générateur d'Analyse Financière\",\n    description=\"Sélectionnez un projet et obtenez une analyse financière détaillée.\"\n)\n\n# Launch the app\napp.launch()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkqsXj_0cvud","outputId":"236a45b4-f31b-40ab-c104-53c2266167e7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"eRODDSkNcwUV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"k1AWLpcocwW3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"RhTuzMhDcwZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"BdQtmXwRcwbk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JRrY92dDcwe9"},"execution_count":null,"outputs":[]}]}