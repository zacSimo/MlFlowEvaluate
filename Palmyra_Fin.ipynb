{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Palmyra-Fin",
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1bc7a338027348269a710472eec9f8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0bffed3a7004f6481877185bb839a9d",
              "IPY_MODEL_de123bd438ab4f83a70a8ba1ddabeb76",
              "IPY_MODEL_236c1df453544178891c3dd278d70bf1"
            ],
            "layout": "IPY_MODEL_00262bb670e8405d9f73b66141939dc2"
          }
        },
        "b0bffed3a7004f6481877185bb839a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bfe93f5d08949198183b0ec90e5872d",
            "placeholder": "​",
            "style": "IPY_MODEL_eb86f5f2a08d4c9eb69888980a97e47b",
            "value": "Map:   0%"
          }
        },
        "de123bd438ab4f83a70a8ba1ddabeb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efa98c686a5e4295b05a185cf4dd6a82",
            "max": 4924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f125850eac0444d2a2603e904bc28ef0",
            "value": 0
          }
        },
        "236c1df453544178891c3dd278d70bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85fa333ad5d24d28b1912cfc916bf405",
            "placeholder": "​",
            "style": "IPY_MODEL_5036763a5dab4e5396882437cc1238ff",
            "value": " 0/4924 [00:00&lt;?, ? examples/s]"
          }
        },
        "00262bb670e8405d9f73b66141939dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bfe93f5d08949198183b0ec90e5872d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb86f5f2a08d4c9eb69888980a97e47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efa98c686a5e4295b05a185cf4dd6a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f125850eac0444d2a2603e904bc28ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85fa333ad5d24d28b1912cfc916bf405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5036763a5dab4e5396882437cc1238ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zacSimo/MlFlowEvaluate/blob/main/Palmyra_Fin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tester le Pamyra-Fin, a powerfull designed for Finance\n",
        "# Palmyra-Fin-70B-32k is intended for use in English for financial analysis\n",
        "# Use with transformers\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-08-28T08:05:44.699069Z",
          "iopub.execute_input": "2024-08-28T08:05:44.699919Z",
          "iopub.status.idle": "2024-08-28T08:05:49.035078Z",
          "shell.execute_reply.started": "2024-08-28T08:05:44.699875Z",
          "shell.execute_reply": "2024-08-28T08:05:49.034274Z"
        },
        "trusted": true,
        "id": "8Z8eoCLbdNOd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hf connection\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "login(\n",
        "  token=userdata.get(\"HF_RW_token\"), # Retrieve my HF_TOKEN stored in Google Colab Secrets\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T08:05:49.036594Z",
          "iopub.execute_input": "2024-08-28T08:05:49.037003Z",
          "iopub.status.idle": "2024-08-28T08:05:49.387998Z",
          "shell.execute_reply.started": "2024-08-28T08:05:49.036969Z",
          "shell.execute_reply": "2024-08-28T08:05:49.387062Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL2fyO2SdNOe",
        "outputId": "73e8af66-4228-410c-e68f-f01d18b253e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# init params\n",
        "\n",
        "model_id = \"Writer/Palmyra-Fin-70B-32K\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Import flash_attn\n",
        "# from flash_attn import flash_attn_func\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    # attn_implementation=\"flash_attention_2\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "QFHhYg0RJz7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a highly knowledge and experienced expert in the financial sector, possessing extensive knowledge and practical expertise in financial analysis, markets, investments, and economic principles.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Can you explain how central banks printing more money (quantitative easing) affects the stock market and how investors might react to it?\",\n",
        "    },\n",
        "]\n",
        "\n",
        "input_ids = tokenizer.apply_chat_template(\n",
        "    messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "gen_conf = {\n",
        "    \"max_new_tokens\": 1024,\n",
        "    \"eos_token_id\": tokenizer.eos_token_id,\n",
        "    \"temperature\": 0.0,\n",
        "    \"top_p\": 0.9,\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T08:05:49.389468Z",
          "iopub.execute_input": "2024-08-28T08:05:49.389783Z"
        },
        "trusted": true,
        "id": "5W8SdlkvdNOf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and configure the tokenizer\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "kJmax2JmL7TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets -q\n",
        "!pip install peft -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-UUpCT-UAM2",
        "outputId": "31a2fa72-f110-47a2-b2f4-5603b5764335"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/527.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m522.2/527.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from peft import (LoraConfig, get_peft_model, prepare_model_for_kbit_training)\n",
        "from transformers import (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline)\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "KJgN5qMLSNSN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the financial dataset\n",
        "file_path = '/content/ValorizationData.xlsx'  # Update with the correct path if different\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "# print(df.head())\n",
        "\n",
        "# Preprocessing: Handle missing values and prepare inputs and targets\n",
        "df.fillna('', inplace=True)\n",
        "\n",
        "df = df[df['ValorizationComment'].str.len() >= 30]"
      ],
      "metadata": {
        "id": "0OzBIs6PNmaV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the text field in French\n",
        "df['text'] = df.apply(lambda row: (\n",
        "    f\"\"\"Project {row['Saphyr Reference']} in {row['Year']}-{row['Month']}\n",
        "    forcast costs {row['Forecast_M-1 (Cost)']}, valorization costs {row['Valorization (Cost)']},\n",
        "    forcast costs {row['Forecast_M-1 (Days)']}, valorization days {row['Valorization (Days)']},\n",
        "    forecast_M-1 margin% {row['Forecast_M-1 (Margin%)']}, valorization margin% {row['Valorization (Margin%)']},\n",
        "    forecast_M-1 turnover {row['Forecast_M-1 (Turnover)']},\n",
        "    valorization Turnover {row['Valorization (Turnover)']}.\"\"\"\n",
        "), axis=1)\n",
        "\n",
        "# Display the first few rows to verify the changes\n",
        "# Set display option to show full text in columns\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "EOaH6AVOQbRw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input and target columns\n",
        "from datasets import Dataset\n",
        "inputs = df['text'].tolist()\n",
        "targets = df['ValorizationComment'].tolist()\n",
        "\n",
        "# Create a dataset\n",
        "data = {\n",
        "    'text': inputs,\n",
        "    'target_text': targets\n",
        "}\n",
        "\n",
        "dataset = Dataset.from_pandas(pd.DataFrame(data))"
      ],
      "metadata": {
        "id": "Rg6w9m1cTN-F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the response template for the solutions\n",
        "response_template = \"### Financial analysis of the project :\"\n",
        "\n",
        "def create_text_field(sample):\n",
        "      return {\n",
        "          \"text\": f\"{sample['text']}\\n{response_template} {sample['target_text']}\"\n",
        "        }\n",
        "\n",
        "dataset = dataset.map(create_text_field, remove_columns=dataset.features, batched=False)"
      ],
      "metadata": {
        "id": "n5QSkoc_V3o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the dataset\n",
        "def tokenize_function(sample):\n",
        "    return tokenizer(\n",
        "        sample['text'],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # Use \"max_length\" if consistent length is needed\n",
        "        max_length=1024  # Adjust based on your model's expected input size\n",
        "    )\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361,
          "referenced_widgets": [
            "1bc7a338027348269a710472eec9f8c1",
            "b0bffed3a7004f6481877185bb839a9d",
            "de123bd438ab4f83a70a8ba1ddabeb76",
            "236c1df453544178891c3dd278d70bf1",
            "00262bb670e8405d9f73b66141939dc2",
            "1bfe93f5d08949198183b0ec90e5872d",
            "eb86f5f2a08d4c9eb69888980a97e47b",
            "efa98c686a5e4295b05a185cf4dd6a82",
            "f125850eac0444d2a2603e904bc28ef0",
            "85fa333ad5d24d28b1912cfc916bf405",
            "5036763a5dab4e5396882437cc1238ff"
          ]
        },
        "id": "T9cxQzZPbdIC",
        "outputId": "d2a11923-ec65-4ee2-de9a-1caa337337bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4924 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bc7a338027348269a710472eec9f8c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-dcc6735eb88a>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Apply tokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtokenized_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         }\n\u001b[1;32m    566\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3165\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3166\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3167\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3168\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3556\u001b[0m                         )  # Something simpler?\n\u001b[1;32m   3557\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3558\u001b[0;31m                             batch = apply_function_on_filtered_inputs(\n\u001b[0m\u001b[1;32m   3559\u001b[0m                                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3560\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3425\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3427\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3428\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3429\u001b[0m                 processed_inputs = {\n",
            "\u001b[0;32m<ipython-input-8-dcc6735eb88a>\u001b[0m in \u001b[0;36mtokenize_function\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tokenize the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     return tokenizer(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from datetime import datetime\n",
        "# LoRA config based on QLoRA paper & Sebastian Raschka experiment\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,       # Moderate alpha for balanced scaling\n",
        "    lora_dropout=0.05,   # Standard dropout to avoid overfitting\n",
        "    r=64,                # Moderate rank for expressiveness\n",
        "    bias=\"none\",         # No bias adaptation\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    # target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj']  # Key projection layers for adaptation\n",
        ")\n",
        "\n",
        "# Define training arguments for lower memory usage\n",
        "training_arguments = TrainingArguments(\n",
        "    # Set this to mlflow for logging your training\n",
        "    report_to=\"mlflow\",\n",
        "    output_dir=\"./gcolab_res\",\n",
        "    # evaluation_strategy=\"steps\",\n",
        "    # do_eval=True,\n",
        "    optim=\"adamw_torch\",  # Use a simpler optimizer\n",
        "    per_device_train_batch_size=1,  # Reduce batch size to fit memory constraints\n",
        "    gradient_accumulation_steps=16,  # Increase accumulation steps to compensate for small batch size\n",
        "    per_device_eval_batch_size=1,  # Reduce eval batch size\n",
        "    log_level=\"info\",\n",
        "    save_steps=50,  # Save less frequently if needed\n",
        "    logging_steps=25,  # Log less frequently to reduce overhead\n",
        "    learning_rate=1e-4,  # Use a lower learning rate\n",
        "    # eval_steps=100,  # Evaluate less frequently\n",
        "    num_train_epochs=1,  # Reduce the number of epochs for quick testing\n",
        "    max_steps=500,  # Limit the total number of steps for quick testing\n",
        "    warmup_steps=50,  # Reduce warmup steps\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    fp16=True,  # Enable mixed-precision training\n",
        "    # Name the MLflow run\n",
        "    run_name=f\"{model_id}-QLoRA-{datetime.now().strftime('%Y-%m-%d-%H-%M-%s')}\",\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(model, peft_config)\n",
        "peft_model.print_trainable_parameters()\n",
        "\n",
        "\n",
        "\n",
        "training_arguments = TrainingArguments(output_dir = \"./gcolab_res\", per_device_train_batch_size = 4, max_steps = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "IwpkoqvHcIoH",
        "outputId": "b1c34bd6-19a9-4c62-f9ac-824dc5b21253"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_id' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2146d0eb5943>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Enable mixed-precision training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Name the MLflow run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{model_id}-QLoRA-{datetime.now().strftime('%Y-%m-%d-%H-%M-%s')}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_id' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=peft_model,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        "    args=training_arguments,\n",
        ")\n"
      ],
      "metadata": {
        "id": "nPKqtOcOb5iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dagshub -q\n",
        "!pip install tiktoken -q\n",
        "!pip install mlflow==2.15.0 -q"
      ],
      "metadata": {
        "id": "2q9ZRxyYcGrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DAGSHUB_USER_NAME = \"zsimale\"\n",
        "DAGSHUB_EMAIL = \"zsimale@gmail.com\"\n",
        "BRANCH = \"main\"\n",
        "DAGSHUB_REPO_NAME = \"evalSIP2llms\"\n",
        "DAGSHUB_TOKEN = userdata.get(\"DagsHub_Token\")"
      ],
      "metadata": {
        "id": "l2ca0TrPdEQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email {DAGSHUB_EMAIL}\n",
        "!git config --global user.name {DAGSHUB_USER_NAME}"
      ],
      "metadata": {
        "id": "yNWKX7y1dwuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://{DAGSHUB_USER_NAME}:{DAGSHUB_TOKEN}@dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO_NAME}.git"
      ],
      "metadata": {
        "id": "P64iv8a7d20w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {DAGSHUB_REPO_NAME}"
      ],
      "metadata": {
        "id": "bMrsb09rd6Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"MLFLOW_TRACKING_URI\"] = f\"https://dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO_NAME}.mlflow\"\n",
        "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = DAGSHUB_USER_NAME\n",
        "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = DAGSHUB_TOKEN"
      ],
      "metadata": {
        "id": "xfK--BsdeDeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_experiment(name):\n",
        "    exp = mlflow.get_experiment_by_name(name)\n",
        "    if exp is None:\n",
        "        exp_id = mlflow.create_experiment(name)\n",
        "        return exp_id\n",
        "    return exp.experiment_id"
      ],
      "metadata": {
        "id": "a7aR2osugKwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
        "print(get_experiment(\"experiment_mlops_test\"))"
      ],
      "metadata": {
        "id": "5tkCvf-neGAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_data_json = {\n",
        "    \"inputs\": [\"Financial analysis for the PA-07783 project in 2023.0-12.0:\\n- Forecast costs: 0.0\\n- Valorization costs: -130355.0\\n- Forecast days: 0.0\\n- Valorization days: 449.88\\n- Forecast margin: \\n- Valuation margin: \\n- Forecast turnover: 0.0\\n- Valuation turnover: 0.0\\n\\nPlease do a financial analysis of the project.\"\n",
        "              ],\n",
        "    \"ground_truth\": [\"Financial analysis of project PA-07783 for the month of December 2023:\\n\\n. There is an error in the data provided. The valuation turnover should be €130,355, because it is the sum of the valuation costs.\\n\\nIndeed, the December turnover is zero because the project is in the process of being closed and the last services were invoiced in January 2024.\\n\\nHere is the financial analysis of the project:\\n- December turnover: €0\\n- January turnover: €0\\n- February turnover: €0\\n- March turnover: €0 \\n- April turnover: €0\\n- May turnover: €0\\n- June turnover: €0\\n- July turnover: €0\\n- August turnover: €0\\n- Turnover from September: €0\\n- October turnover: €0\\n- November turnover: €0\\n- December turnover: €0\\n- January turnover: €0\\n- February turnover: €0\\n n- Total turnover: €0\\n\\nThe valuation turnover for December is €130,355.\\n\\nThe valuation margin is 0.00 because the turnover is zero.\\n\\nThere is an error in the data provided. The valuation turnover should be €130,355, because this is the sum of the costs.\"\n",
        "                    ]\n",
        "}\n",
        "\n",
        "eval_data_df = pd.DataFrame(eval_data_json)\n",
        "eval_data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "tFZzHuiQetzw",
        "outputId": "3138b7b0-40be-4033-9e61-c0cd1c702d9a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                     inputs  \\\n",
              "0  Financial analysis for the PA-07783 project in 2023.0-12.0:\\n- Forecast costs: 0.0\\n- Valorization costs: -130355.0\\n- Forecast days: 0.0\\n- Valorization days: 449.88\\n- Forecast margin: \\n- Valuation margin: \\n- Forecast turnover: 0.0\\n- Valuation turnover: 0.0\\n\\nPlease do a financial analysis of the project.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ground_truth  \n",
              "0  Financial analysis of project PA-07783 for the month of December 2023:\\n\\n. There is an error in the data provided. The valuation turnover should be €130,355, because it is the sum of the valuation costs.\\n\\nIndeed, the December turnover is zero because the project is in the process of being closed and the last services were invoiced in January 2024.\\n\\nHere is the financial analysis of the project:\\n- December turnover: €0\\n- January turnover: €0\\n- February turnover: €0\\n- March turnover: €0 \\n- April turnover: €0\\n- May turnover: €0\\n- June turnover: €0\\n- July turnover: €0\\n- August turnover: €0\\n- Turnover from September: €0\\n- October turnover: €0\\n- November turnover: €0\\n- December turnover: €0\\n- January turnover: €0\\n- February turnover: €0\\n n- Total turnover: €0\\n\\nThe valuation turnover for December is €130,355.\\n\\nThe valuation margin is 0.00 because the turnover is zero.\\n\\nThere is an error in the data provided. The valuation turnover should be €130,355, because this is the sum of the costs.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4603f31f-9c4d-4d43-bbbc-aed72728a435\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>ground_truth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Financial analysis for the PA-07783 project in 2023.0-12.0:\\n- Forecast costs: 0.0\\n- Valorization costs: -130355.0\\n- Forecast days: 0.0\\n- Valorization days: 449.88\\n- Forecast margin: \\n- Valuation margin: \\n- Forecast turnover: 0.0\\n- Valuation turnover: 0.0\\n\\nPlease do a financial analysis of the project.</td>\n",
              "      <td>Financial analysis of project PA-07783 for the month of December 2023:\\n\\n. There is an error in the data provided. The valuation turnover should be €130,355, because it is the sum of the valuation costs.\\n\\nIndeed, the December turnover is zero because the project is in the process of being closed and the last services were invoiced in January 2024.\\n\\nHere is the financial analysis of the project:\\n- December turnover: €0\\n- January turnover: €0\\n- February turnover: €0\\n- March turnover: €0 \\n- April turnover: €0\\n- May turnover: €0\\n- June turnover: €0\\n- July turnover: €0\\n- August turnover: €0\\n- Turnover from September: €0\\n- October turnover: €0\\n- November turnover: €0\\n- December turnover: €0\\n- January turnover: €0\\n- February turnover: €0\\n n- Total turnover: €0\\n\\nThe valuation turnover for December is €130,355.\\n\\nThe valuation margin is 0.00 because the turnover is zero.\\n\\nThere is an error in the data provided. The valuation turnover should be €130,355, because this is the sum of the costs.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4603f31f-9c4d-4d43-bbbc-aed72728a435')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4603f31f-9c4d-4d43-bbbc-aed72728a435 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4603f31f-9c4d-4d43-bbbc-aed72728a435');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_2652f3bf-c857-46dd-a4a5-366f21d73005\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('eval_data_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2652f3bf-c857-46dd-a4a5-366f21d73005 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('eval_data_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "eval_data_df",
              "summary": "{\n  \"name\": \"eval_data_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"inputs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Financial analysis for the PA-07783 project in 2023.0-12.0:\\n- Forecast costs: 0.0\\n- Valorization costs: -130355.0\\n- Forecast days: 0.0\\n- Valorization days: 449.88\\n- Forecast margin: \\n- Valuation margin: \\n- Forecast turnover: 0.0\\n- Valuation turnover: 0.0\\n\\nPlease do a financial analysis of the project.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Financial analysis of project PA-07783 for the month of December 2023:\\n\\n. There is an error in the data provided. The valuation turnover should be \\u20ac130,355, because it is the sum of the valuation costs.\\n\\nIndeed, the December turnover is zero because the project is in the process of being closed and the last services were invoiced in January 2024.\\n\\nHere is the financial analysis of the project:\\n- December turnover: \\u20ac0\\n- January turnover: \\u20ac0\\n- February turnover: \\u20ac0\\n- March turnover: \\u20ac0 \\n- April turnover: \\u20ac0\\n- May turnover: \\u20ac0\\n- June turnover: \\u20ac0\\n- July turnover: \\u20ac0\\n- August turnover: \\u20ac0\\n- Turnover from September: \\u20ac0\\n- October turnover: \\u20ac0\\n- November turnover: \\u20ac0\\n- December turnover: \\u20ac0\\n- January turnover: \\u20ac0\\n- February turnover: \\u20ac0\\n n- Total turnover: \\u20ac0\\n\\nThe valuation turnover for December is \\u20ac130,355.\\n\\nThe valuation margin is 0.00 because the turnover is zero.\\n\\nThere is an error in the data provided. The valuation turnover should be \\u20ac130,355, because this is the sum of the costs.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\"max_new_tokens\": 200}\n",
        "signature = mlflow.models.infer_signature(\n",
        "    params=params,\n",
        ")\n",
        "\n",
        "with mlflow.start_run(experiment_id=get_experiment(\"experiment_mlops_test\")):\n",
        "    mlflow.log_params(peft_config.to_dict())\n",
        "\n",
        "#     log llama model\n",
        "    model_info = mlflow.transformers.log_model(\n",
        "        transformers_model={\"model\": trainer.model, \"tokenizer\": tokenizer},\n",
        "#         prompt_template=prompt_template,\n",
        "        signature=signature,\n",
        "        artifact_path=\"model\",  # This is a relative path to save model files within MLflow run\n",
        "    )\n",
        "\n",
        "    # Evaluate saved model\n",
        "    results = mlflow.evaluate(\n",
        "        model_info.model_uri, # model_info.model_uri\n",
        "        eval_data_df,\n",
        "        targets=\"ground_truth\",\n",
        "        model_type=\"question-answering\",\n",
        "        extra_metrics=[mlflow.metrics.toxicity(), mlflow.metrics.latency(), mlflow.metrics.rougeL(), mlflow.metrics.flesch_kincaid_grade_level()],\n",
        "    )"
      ],
      "metadata": {
        "id": "KBnA5288hOP-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}